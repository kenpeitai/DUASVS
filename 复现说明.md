《复现工程设计说明（中文版）》。
________________________________________
短视频流媒体 OOD 复现工程说明文档
（基于 KuaiRec + 网络 Trace）
________________________________________
0. 研究目标说明（非常重要）
本工程的研究目标是：
研究短视频流媒体决策模型在网络分布发生变化（OOD）时的泛化能力。
本工程不追求：
	复现 DUASVS 等论文中的具体数值（如 70%+ data saving）
	复刻商业平台内部实验环境
而是：
	在统一的仿真环境中
	使用公开可复现的数据集
	对不同方法在 OOD 网络条件下的鲁棒性进行公平评估
________________________________________
1. 数据集总体设计思路
整个短视频 streaming episode 由 两部分数据解耦组合而成：
真实用户行为（KuaiRec）
          +
真实网络动态（FCC / MONROE / Belgium）
          =
短视频流媒体仿真环境
这样做的目的：
	保留真实用户观看/切换行为
	控制网络分布作为 OOD 来源
	避免 vendor-specific 偏置
________________________________________
2. 用户与视频行为数据（KuaiRec）
2.1 KuaiRec 的角色
KuaiRec 是一个 短视频推荐数据集，不是流媒体系统数据集。
在本工程中，KuaiRec 仅用于提供真实的用户观看行为和视频属性，不涉及任何网络或下载信息。
________________________________________
2.2 使用的字段（最小必要集）
从 KuaiRec 中使用以下字段（按时间排序）：
	user_id
	video_id
	video_duration（视频物理时长，秒）
	watch_time（用户实际观看时长，秒）
可直接派生的量：
	是否中途切换：
	is_skip = (watch_time < video_duration)
	实际观看比例：
	watch_ratio = watch_time / video_duration
________________________________________
2.3 Session / Episode 构造方式
	一个 episode = 用户一次连续刷视频的 session
	构造方式：
	选定一个用户
	取其时间上连续的一段视频序列
	episode 长度可变（符合真实短视频使用习惯）
KuaiRec 提供的是真实用户切换行为，无需额外建模用户意图。
________________________________________
3. 网络数据集（独立于 KuaiRec）
3.1 网络数据的作用
网络 trace 用于：
	模拟视频下载吞吐
	触发 rebuffer
	计算下载时间与 data waste
	构造 OOD 分布偏移
网络数据 与用户行为完全解耦。
________________________________________
3.2 使用的网络数据集
数据集	用途
FCC（M-Lab）	训练 / In-D
MONROE – Italy	OOD 测试
MONROE – Sweden	OOD 测试
Belgium LTE	OOD 测试
每条 trace 为时间序列：
throughput[t]   # Mbps 或 kbps
如采样率不同，需要统一重采样（例如 1 秒）。
________________________________________
4. 码率与视频大小建模（需补充）
KuaiRec 不包含视频编码信息，因此需要人工建模。
________________________________________
4.1 码率档位（Bitrate Ladder）
定义全局固定的码率集合，例如：
bitrates = [0.3, 0.75, 1.5, 3.0] Mbps
所有方法、所有数据集统一使用。
________________________________________
4.2 视频大小计算
对任意视频（时长为 L 秒）：
video_size(bitrate) = bitrate × L
这是抽象建模，不涉及真实视频编码。
________________________________________
5. 流媒体仿真环境（Simulator）
5.1 Episode 结构定义
Episode = {
  network_trace_id,
  throughput[t],
  video_sequence = [
    {
      video_length,
      watch_time,
      bitrate_levels
    },
    ...
  ]
}
	一个 decision step 对应 一个视频
	时间在下载与播放过程中连续推进
________________________________________
5.2 下载与播放逻辑
下载
若为视频 i 选择码率 r_i：
download_time = video_size(r_i) / throughput
下载完成后，视频内容进入 buffer。
________________________________________
播放
	buffer 以 1× 速度消耗
	buffer 归零 → 发生 rebuffer
________________________________________
用户切换与数据浪费
用户仅观看 watch_time 秒：
	若 watch_time < video_length：
	剩余已下载内容 → data waste
	否则：
	无浪费
________________________________________
6. 强化学习建模
6.1 决策粒度
	每个视频一次决策
	非 chunk 级
________________________________________
6.2 状态空间（State）
在请求第 i 个视频时，状态包含：
State 0：历史网络吞吐（核心）
[c_{i-K}, ..., c_{i-1}]
	最近 K 个视频下载的平均吞吐
	OOD 的主要来源
________________________________________
State 1：当前 buffer
buffer_seconds
________________________________________
State 2：当前视频时长
video_length
________________________________________
State 3：上一个视频的码率
previous_bitrate
说明：
视频在不同码率下的 size 不作为状态输入，因为 size 可由 bitrate + duration 确定。
________________________________________
6.3 动作空间（Action）
根据方法复杂度，可选两种：
方案 A：仅控制码率（简化）
action ∈ {bitrate_index}
________________________________________
方案 B：联合控制（DUASVS-style）
action = (bitrate_index, prefetch_threshold)
其中：
prefetch_threshold ∈ {2, 5, 10, 20, 40} 秒
________________________________________
7. Reward 设计（关键）
7.1 数据浪费（Data Waste）
对视频 i：
waste_s_i = downloaded_seconds_i - watched_seconds_i
完全看完则为 0。
在本仓库实现中，最终用于 reward 的“浪费”采用 **数据量**（Mbit）版本：
\[
waste\_mbit_i = bitrate\_mbps_i \cdot waste\_s_i
\]
________________________________________
7.2 QoE 项
论文默认采用 Mao et al.（Pensieve）提出的 QoE 函数：
U =
  Σ log(r_i / r_min)
− Σ |log(r_{i+1} / r_min) − log(r_i / r_min)|
− 2.66 · Σ rebuffer_time_i
其中：
	r_min = 0.2 Mbps
	2.66 是 rebuffer 惩罚系数
📌 这是论文中 Table 7 默认 QoE1。
________________________________________
7.3 最终 Reward
reward_i = QoE_i − λ · waste_mbit_i
	λ：控制省流量强度（单位：reward / Mbit）
	OOD 评估时 固定 λ，不允许按数据集调参
________________________________________
8. 训练与评估协议
8.1 训练（In-D）
	网络：FCC
	用户行为：KuaiRec
	策略：单一共享策略（PPO / A2C 等）
________________________________________
8.2 OOD 测试
	网络：
	MONROE
	MONROE
	用户行为：同一 KuaiRec session
	不允许 retrain / finetune
________________________________________
9. 明确的“不做事项”
	❌ 不实现 DUASVS 的 Integrated Learning
	❌ 不做网络离散分箱
	❌ 不为不同网络单独调 reward
DUASVS-style 方法仅作为 非泛化基线。
________________________________________
10. 总结（一句话版）
本工程使用 KuaiRec 提供真实短视频用户行为，并结合独立的真实网络 trace，构建可复现的短视频流媒体仿真环境，以研究在网络分布变化下不同方法的 OOD 泛化能力。

________________________________________
11. 目录结构（本仓库落地版）

本仓库按本文档实现了 **per-video 仿真 + 训练/评估入口**：
- `envs/duasvs_env.py`：per-video 仿真环境（支持联合动作：Bitrate + Prefetch Threshold）
- `train_duasvs_ppo.py`：PPO 训练入口（In-D：FCC）
- `evaluate_duasvs.py`：多域评估入口（In-D + OOD：MONROE 等）

数据文件（你已准备好）：
- `data/big_matrix_valid_video.csv`：KuaiRec 行为日志（列：`user_id, video_id, play_duration, video_duration, timestamp, ...`）
- `data/fcc_httpgetmt_trace_1s_kbps.csv`：FCC 1s 吞吐（列：`trace_id,t,throughput_kbps`）
- `data/monroe_*.csv`：MONROE 1s 吞吐（列：`trace_id,t,throughput_kbps`）
- `splits/*.txt`：各域 trace id 划分

________________________________________
12. Conda 环境创建（DUASVS）

推荐按 `environment.yml` 一键创建（CPU 版）：

```bash
conda env remove -n DUASVS -y || true
conda env create -f environment.yml
conda activate DUASVS
```

或者用 pip 安装（当你想用 GPU/自定义 torch 时）：

```bash
conda create -n DUASVS python=3.10 -y
conda activate DUASVS
pip install -r requirements.txt
```

验证依赖是否就绪：

```bash
python -c "import torch, pandas, gymnasium; print('torch', torch.__version__)"
```

________________________________________
13. 按文档建模的最小可运行复现（训练 + OOD 评估）

### 13.1 In-D 训练（FCC）

本仓库已实现 **联合动作空间（Bitrate + Prefetch Threshold）**：
- **Bitrate**：从 **`[360p, 480p, 720p, 1080p]`** 四档中选择（实现中对应 `video_bitrates_mbps=[0.7,1.2,2.5,5.0]`）
- **Prefetch Threshold**：从 `prefetch_thresholds_s=[1,2,4,6,8,12,18]` 选择

其中 `prefetch_threshold` 在实现中解释为：**“未播放缓冲上限”（秒）**。当未播放缓冲 ≥ threshold 时暂停下载以省流量；当未播放缓冲 < threshold 时继续下载以减少卡顿。这样会形成“卡顿 vs 浪费”的权衡，符合本文档的联合动作设计初衷。

```bash
python train_duasvs_ppo.py \
  --events_csv data/big_matrix_valid_video.csv \
  --traces_csv data/fcc_httpgetmt_trace_1s_kbps.csv \
  --trace_ids_file splits/fcc_train_trace_ids.txt \
  --total_steps 50000 \
  --lambda_waste 1.0 \
  --prefetch_thresholds 1,2,4,6,8,12,18 \
  --run_name duasvs_ppo
```

输出：
- checkpoint：`checkpoints/duasvs_ppo.pt`
- 训练日志：`checkpoints/duasvs_ppo_train.csv`

### 13.2 OOD 测试（MONROE / Belgium 可按同样方式扩展）

```bash
python evaluate_duasvs.py --ckpt checkpoints/duasvs_ppo.pt \
  --prefetch_thresholds 1,2,4,6,8,12,18 \
  --eval fcc,data/fcc_httpgetmt_trace_1s_kbps.csv,splits/fcc_test_trace_ids.txt \
  --eval monroe_sweden,data/monroe_sweden.csv,splits/monroe_sweden_ids.txt \
  --eval monroe_spain,data/monroe_spain.csv,splits/monroe_spain_ids.txt \
  --eval monroe_italy,data/monroe_italy.csv,splits/monroe_italy_ids.txt
```

输出：
- `eval_outputs/<run_name>/episodes.csv`
- `eval_outputs/<run_name>/summary.csv`


详细设计：
短视频流媒体 RL 建模设计
状态空间、动作空间与参数设定（最终版）
一、决策粒度（先定基本单位）
	决策粒度：per-video（每个视频一次决策）
	不是 chunk 级
	一个 episode = 一个用户刷短视频 session
这点与 DUASVS 完全一致，对短视频场景是合理建模。
二、状态空间（State Space）
在请求第 i 个视频时，Agent 接收状态向量 S_i。
状态总览
S_i=[((c_i)┬⏟)┬"network" ,((b_i)┬⏟)┬"buffer" ,((L_i)┬⏟)┬"video" ,((r_(i-1))┬⏟)┬"history" ]

2.1 历史网络吞吐（核心状态）
定义
c_i={c_(i-K),c_(i-K+1),…,c_(i-1)}

	含义：最近 K 个视频下载阶段的平均吞吐
	单位：Mbps
	来源：network trace replay
参数设定（推荐）
K = 5 或 8 
	K 太小：网络估计不稳
	K 太大：引入历史噪声，不利于 OOD
预处理（强烈建议）
c_norm = clip(c / c_ref, 0, c_max) 
示例：
c_ref = 5 Mbps c_max = 3 
📌 这是 OOD 泛化的关键设计点
避免模型记住“国家/网络类型的绝对数值”。
2.2 当前播放缓冲区（Buffer）
定义
b_i="buffer occupancy (seconds)"

	表示当前已下载、可播放的内容时长
	连续值
参数设定
b_max = 60 s b_norm = min(b_i / b_max, 1.0) 
📌 buffer 是 rebuffer 风险的直接 proxy。
2.3 当前视频物理时长（Video Length）
定义
L_i = \text{video_duration (seconds)}
	来自 KuaiRec
	与用户切换行为强相关
参数设定（归一化）
L_max = 60 s L_norm = min(L_i / L_max, 1.0) 
📌 不引入 watch_time，避免“泄露用户未来行为”。
2.4 上一个视频的码率（Bitrate History）
定义
r_(i-1)∈{0,1,…,H-1}

	上一个视频选择的 bitrate index
编码方式（推荐）
	one-hot 编码，或
	归一化标量：
r_norm = r_{i-1} / (H - 1) 
📌 用于惩罚码率震荡。
2.5 最终状态维度示例
假设：
	K=5
	bitrate levels H=4
则：
state_dim = 5 (throughput) + 1 (buffer) + 1 (video length) + 1 (prev bitrate) = 8 
这是一个非常干净、稳定、可泛化的状态设计。
三、动作空间（Action Space）
根据实验复杂度，提供 两种可选方案。
3.1 方案 A：仅控制码率（推荐主实验）
动作定义
a_i∈{0,1,…,H-1}

	表示选择第 a_i 个码率档位
码率参数设定（示例）
bitrates = [0.3, 0.75, 1.5, 3.0] Mbps H = 4 
对应视频大小
〖"size" 〗_i="bitrates"[a_i]×L_i

	动作空间小
	训练稳定
	OOD 结论最干净
3.2 方案 B：联合控制码率 + 预取（DUASVS-style）
可作为 ablation / 扩展实验
动作定义
a_i=(r_i,p_i)

其中：
	r_i：码率 index
	p_i：预取阈值 index
预取阈值集合
prefetch_thresholds = [2, 5, 10, 20, 40] seconds P = 5 
联合动作空间大小
|A| = H × P = 4 × 5 = 20 
📌 PPO 完全可以稳定处理。
四、环境动态参数（Simulator Parameters）
4.1 播放参数
playback_rate = 1.0 × 
4.2 下载时间
T_download=〖"size" 〗_i/"throughput" 

4.3 Rebuffer 判定
	若 buffer 在播放过程中降为 0：
rebuffer_time += duration 
4.4 Data Waste 计算
waste_i = max(0, downloaded_time - watch_time) 
五、Reward 设计（带参数）
5.1 QoE 项
〖"QoE" 〗_i=α⋅log⁡(〖"bitrate" 〗_i)-β⋅〖"rebuffer" 〗_i-γ⋅∣〖"bitrate" 〗_i-〖"bitrate" 〗_(i-1)∣

推荐参数
α = 1.0 β = 2.66 γ = 0.1 ，Pensieve的 QoE 定义
5.2 数据浪费惩罚
〖"waste" 〗_i=〖"downloaded" 〗_i-〖"watched" 〗_i

5.3 最终 Reward
r_i=〖"QoE" 〗_i-λ⋅〖"waste" 〗_i

λ 参数建议
λ = 0.5 ~ 1.0 
	训练 / 测试固定
	不随网络变化
六、PPO 训练相关参数（建议）
optimizer = Adam lr = 3e-4 gamma = 0.99 lambda(GAE) = 0.95 clip_ratio = 0.2 entropy_coef = 0.01 rollout_steps = 2048 batch_size = 256 update_epochs = 10 

